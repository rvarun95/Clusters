{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install numpy scipy scikit-learn pandas joblib\n",
    "!pip install deap update_checker tqdm stopit\n",
    "!pip install dask[delayed] dask-ml\n",
    "!pip install scikit-mdr skrebate\n",
    "!pip install tpot\n",
    "!conda install -c conda-forge ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kVeq8No6_GU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "random.seed(100)\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 64638,
     "status": "ok",
     "timestamp": 1568028337869,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "g0c0BSiwoNhX",
    "outputId": "494e28c3-11de-4251-d32d-5400a36eeca7"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OR-7uess7z5C"
   },
   "outputs": [],
   "source": [
    "#os.chdir('/home/')\n",
    "train = pd.read_csv('exoTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9487,
     "status": "ok",
     "timestamp": 1568028354021,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "UfSk8TfX6_Gb",
    "outputId": "87ce4bb4-b331-427e-e0ba-480b531027fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5087, 3198)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9389,
     "status": "ok",
     "timestamp": 1568028355032,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "Xxoh5Q4i6_Gk",
    "outputId": "aab31422-8d21-45fc-874a-0826800e0127"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LABEL</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LABEL   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pee6CP7AL09u"
   },
   "outputs": [],
   "source": [
    "train.rename(columns={'LABEL': 'class'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "debKv1XXMFbP"
   },
   "outputs": [],
   "source": [
    "#train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1250,
     "status": "ok",
     "timestamp": 1568028358207,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "fnYsYRNkMFbV",
    "outputId": "39701332-2eab-4058-ac1c-f53a20696d6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2249,
     "status": "ok",
     "timestamp": 1568028360050,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "9X2Pa8AFMFba",
    "outputId": "78854076-9fc9-4acc-f825-0a8cf47820c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5087, 3198)\n",
      "(5087, 3198)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train=train.dropna()\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1342,
     "status": "ok",
     "timestamp": 1568028360076,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "rp9czA7bMFbf",
    "outputId": "09bba014-f939-4f8e-d5c1-688f0aa96777"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VYcF0monMFbj"
   },
   "outputs": [],
   "source": [
    "for col_name in train.columns:\n",
    "    if(train[col_name].dtype == 'object'):\n",
    "        print(col_name)\n",
    "        train[col_name]= train[col_name].astype('category')\n",
    "        train[col_name] = train[col_name].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1568028361436,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "h7w5IcHSMFbk",
    "outputId": "6d247c13-f53d-414b-df26-5c11c81181a6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class   FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7  \\\n",
       "0      2    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   \n",
       "1      2   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   \n",
       "2      2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   \n",
       "3      2   326.52   347.39   302.35   298.13   317.74   312.70  322.33   \n",
       "4      2 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34   \n",
       "\n",
       "    FLUX.8  FLUX.9  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0   -96.27  -79.89  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1   -85.33  -83.97  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2   486.39  436.56  ...     -71.69      13.31      13.31     -29.89   \n",
       "3   311.31  312.42  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -1022.71 -989.57  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3198 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CvedGkh_MFbn"
   },
   "outputs": [],
   "source": [
    "X = train.drop('class', axis=1)  \n",
    "#X = X.drop('Loan_ID',axis=1)\n",
    "y = train['class'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1340,
     "status": "ok",
     "timestamp": 1568028363961,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "ue4VdzVAMFbs",
    "outputId": "8781b799-38bb-471c-d172-a7582f19ebf7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>93.85</td>\n",
       "      <td>83.81</td>\n",
       "      <td>20.10</td>\n",
       "      <td>-26.98</td>\n",
       "      <td>-39.56</td>\n",
       "      <td>-124.71</td>\n",
       "      <td>-135.18</td>\n",
       "      <td>-96.27</td>\n",
       "      <td>-79.89</td>\n",
       "      <td>-160.17</td>\n",
       "      <td>...</td>\n",
       "      <td>-78.07</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>-102.15</td>\n",
       "      <td>25.13</td>\n",
       "      <td>48.57</td>\n",
       "      <td>92.54</td>\n",
       "      <td>39.32</td>\n",
       "      <td>61.42</td>\n",
       "      <td>5.08</td>\n",
       "      <td>-39.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-38.88</td>\n",
       "      <td>-33.83</td>\n",
       "      <td>-58.54</td>\n",
       "      <td>-40.09</td>\n",
       "      <td>-79.31</td>\n",
       "      <td>-72.81</td>\n",
       "      <td>-86.55</td>\n",
       "      <td>-85.33</td>\n",
       "      <td>-83.97</td>\n",
       "      <td>-73.38</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.28</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-32.21</td>\n",
       "      <td>-24.89</td>\n",
       "      <td>-4.86</td>\n",
       "      <td>0.76</td>\n",
       "      <td>-11.70</td>\n",
       "      <td>6.46</td>\n",
       "      <td>16.00</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>532.64</td>\n",
       "      <td>535.92</td>\n",
       "      <td>513.73</td>\n",
       "      <td>496.92</td>\n",
       "      <td>456.45</td>\n",
       "      <td>466.00</td>\n",
       "      <td>464.50</td>\n",
       "      <td>486.39</td>\n",
       "      <td>436.56</td>\n",
       "      <td>484.39</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.69</td>\n",
       "      <td>13.31</td>\n",
       "      <td>13.31</td>\n",
       "      <td>-29.89</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>5.06</td>\n",
       "      <td>-11.80</td>\n",
       "      <td>-28.91</td>\n",
       "      <td>-70.02</td>\n",
       "      <td>-96.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>326.52</td>\n",
       "      <td>347.39</td>\n",
       "      <td>302.35</td>\n",
       "      <td>298.13</td>\n",
       "      <td>317.74</td>\n",
       "      <td>312.70</td>\n",
       "      <td>322.33</td>\n",
       "      <td>311.31</td>\n",
       "      <td>312.42</td>\n",
       "      <td>323.33</td>\n",
       "      <td>...</td>\n",
       "      <td>5.71</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>-3.73</td>\n",
       "      <td>30.05</td>\n",
       "      <td>20.03</td>\n",
       "      <td>-12.67</td>\n",
       "      <td>-8.77</td>\n",
       "      <td>-17.31</td>\n",
       "      <td>-17.35</td>\n",
       "      <td>13.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-1107.21</td>\n",
       "      <td>-1112.59</td>\n",
       "      <td>-1118.95</td>\n",
       "      <td>-1095.10</td>\n",
       "      <td>-1057.55</td>\n",
       "      <td>-1034.48</td>\n",
       "      <td>-998.34</td>\n",
       "      <td>-1022.71</td>\n",
       "      <td>-989.57</td>\n",
       "      <td>-970.88</td>\n",
       "      <td>...</td>\n",
       "      <td>-594.37</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-401.66</td>\n",
       "      <td>-357.24</td>\n",
       "      <td>-443.76</td>\n",
       "      <td>-438.54</td>\n",
       "      <td>-399.71</td>\n",
       "      <td>-384.65</td>\n",
       "      <td>-411.79</td>\n",
       "      <td>-510.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6  FLUX.7   FLUX.8  \\\n",
       "0    93.85    83.81    20.10   -26.98   -39.56  -124.71 -135.18   -96.27   \n",
       "1   -38.88   -33.83   -58.54   -40.09   -79.31   -72.81  -86.55   -85.33   \n",
       "2   532.64   535.92   513.73   496.92   456.45   466.00  464.50   486.39   \n",
       "3   326.52   347.39   302.35   298.13   317.74   312.70  322.33   311.31   \n",
       "4 -1107.21 -1112.59 -1118.95 -1095.10 -1057.55 -1034.48 -998.34 -1022.71   \n",
       "\n",
       "   FLUX.9  FLUX.10  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "0  -79.89  -160.17  ...     -78.07    -102.15    -102.15      25.13   \n",
       "1  -83.97   -73.38  ...      -3.28     -32.21     -32.21     -24.89   \n",
       "2  436.56   484.39  ...     -71.69      13.31      13.31     -29.89   \n",
       "3  312.42   323.33  ...       5.71      -3.73      -3.73      30.05   \n",
       "4 -989.57  -970.88  ...    -594.37    -401.66    -401.66    -357.24   \n",
       "\n",
       "   FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "0      48.57      92.54      39.32      61.42       5.08     -39.54  \n",
       "1      -4.86       0.76     -11.70       6.46      16.00      19.93  \n",
       "2     -20.88       5.06     -11.80     -28.91     -70.02     -96.67  \n",
       "3      20.03     -12.67      -8.77     -17.31     -17.35      13.98  \n",
       "4    -443.76    -438.54    -399.71    -384.65    -411.79    -510.54  \n",
       "\n",
       "[5 rows x 3197 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1247,
     "status": "ok",
     "timestamp": 1568028364466,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "13j_gU8rMEs0",
    "outputId": "437d73ca-e81b-4451-a545-82e470b17c4d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    2\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1242,
     "status": "error",
     "timestamp": 1568028396293,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "fCqdmUMXMEmc",
    "outputId": "f3019607-016d-427d-e9cf-8d4c8e875a04"
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values,train_size=0.90, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1568021884550,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "Rlvq1lriL1Bo",
    "outputId": "32485485-ecac-441c-f2b9-5321a2cc195c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4578, 3197) (509, 3197) (4578,) (509,)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> (4578, 3197) (509, 3197)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "X_train_array=X_train.values\n",
    "X_test_array=X_test.values\n",
    "print(type(X_train_array),type(X_test_array), type(y_train), np.shape(X_train_array), np.shape(X_test_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 899,
     "status": "ok",
     "timestamp": 1568021886379,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "ZtoW7S-jL1D2",
    "outputId": "f6e42f49-3549-400b-f08a-9c7775eb4de1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.64   -0.97    3.36 ...   12.94   34.68   25.63]\n",
      " [  28.71   23.88   14.8  ...   -4.78   11.23    3.46]\n",
      " [ 323.51  285.75  283.15 ... -130.96 -101.02  -85.14]]\n",
      "[1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1949</td>\n",
       "      <td>6.64</td>\n",
       "      <td>-0.97</td>\n",
       "      <td>3.36</td>\n",
       "      <td>-20.28</td>\n",
       "      <td>25.21</td>\n",
       "      <td>14.05</td>\n",
       "      <td>11.92</td>\n",
       "      <td>5.28</td>\n",
       "      <td>2.18</td>\n",
       "      <td>11.89</td>\n",
       "      <td>...</td>\n",
       "      <td>77.05</td>\n",
       "      <td>105.71</td>\n",
       "      <td>131.03</td>\n",
       "      <td>189.64</td>\n",
       "      <td>219.13</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>12.94</td>\n",
       "      <td>34.68</td>\n",
       "      <td>25.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1893</td>\n",
       "      <td>28.71</td>\n",
       "      <td>23.88</td>\n",
       "      <td>14.80</td>\n",
       "      <td>12.61</td>\n",
       "      <td>16.86</td>\n",
       "      <td>17.06</td>\n",
       "      <td>15.61</td>\n",
       "      <td>20.79</td>\n",
       "      <td>11.97</td>\n",
       "      <td>6.54</td>\n",
       "      <td>...</td>\n",
       "      <td>10.93</td>\n",
       "      <td>19.32</td>\n",
       "      <td>7.18</td>\n",
       "      <td>11.95</td>\n",
       "      <td>4.94</td>\n",
       "      <td>1.28</td>\n",
       "      <td>2.97</td>\n",
       "      <td>-4.78</td>\n",
       "      <td>11.23</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4511</td>\n",
       "      <td>323.51</td>\n",
       "      <td>285.75</td>\n",
       "      <td>283.15</td>\n",
       "      <td>237.64</td>\n",
       "      <td>208.31</td>\n",
       "      <td>142.98</td>\n",
       "      <td>78.37</td>\n",
       "      <td>73.03</td>\n",
       "      <td>50.20</td>\n",
       "      <td>23.95</td>\n",
       "      <td>...</td>\n",
       "      <td>-93.96</td>\n",
       "      <td>-99.42</td>\n",
       "      <td>-32.63</td>\n",
       "      <td>-80.77</td>\n",
       "      <td>-29.91</td>\n",
       "      <td>-55.91</td>\n",
       "      <td>-139.32</td>\n",
       "      <td>-130.96</td>\n",
       "      <td>-101.02</td>\n",
       "      <td>-85.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      FLUX.1  FLUX.2  FLUX.3  FLUX.4  FLUX.5  FLUX.6  FLUX.7  FLUX.8  FLUX.9  \\\n",
       "1949    6.64   -0.97    3.36  -20.28   25.21   14.05   11.92    5.28    2.18   \n",
       "1893   28.71   23.88   14.80   12.61   16.86   17.06   15.61   20.79   11.97   \n",
       "4511  323.51  285.75  283.15  237.64  208.31  142.98   78.37   73.03   50.20   \n",
       "\n",
       "      FLUX.10  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  FLUX.3192  \\\n",
       "1949    11.89  ...      77.05     105.71     131.03     189.64     219.13   \n",
       "1893     6.54  ...      10.93      19.32       7.18      11.95       4.94   \n",
       "4511    23.95  ...     -93.96     -99.42     -32.63     -80.77     -29.91   \n",
       "\n",
       "      FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "1949      -6.37      -6.37      12.94      34.68      25.63  \n",
       "1893       1.28       2.97      -4.78      11.23       3.46  \n",
       "4511     -55.91    -139.32    -130.96    -101.02     -85.14  \n",
       "\n",
       "[3 rows x 3197 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_array[1:4])\n",
    "print(y_train[1:4])\n",
    "X_train[1:4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 985,
     "status": "ok",
     "timestamp": 1568021888940,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "BR_sNwGyL1Hx",
    "outputId": "acf62048-e23a-428c-ee6f-18f713763328"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "[[-1549.05 -1576.43 -1553.18 ...   314.58   280.01   306.14]\n",
      " [    5.46    10.28     7.87 ...     2.25    -2.96     8.83]\n",
      " [    2.7     -6.37   -13.93 ...    -4.33    -6.72    -2.13]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FLUX.1</th>\n",
       "      <th>FLUX.2</th>\n",
       "      <th>FLUX.3</th>\n",
       "      <th>FLUX.4</th>\n",
       "      <th>FLUX.5</th>\n",
       "      <th>FLUX.6</th>\n",
       "      <th>FLUX.7</th>\n",
       "      <th>FLUX.8</th>\n",
       "      <th>FLUX.9</th>\n",
       "      <th>FLUX.10</th>\n",
       "      <th>...</th>\n",
       "      <th>FLUX.3188</th>\n",
       "      <th>FLUX.3189</th>\n",
       "      <th>FLUX.3190</th>\n",
       "      <th>FLUX.3191</th>\n",
       "      <th>FLUX.3192</th>\n",
       "      <th>FLUX.3193</th>\n",
       "      <th>FLUX.3194</th>\n",
       "      <th>FLUX.3195</th>\n",
       "      <th>FLUX.3196</th>\n",
       "      <th>FLUX.3197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>509</td>\n",
       "      <td>-1549.05</td>\n",
       "      <td>-1576.43</td>\n",
       "      <td>-1553.18</td>\n",
       "      <td>-1544.52</td>\n",
       "      <td>-1539.99</td>\n",
       "      <td>-1561.30</td>\n",
       "      <td>-1537.07</td>\n",
       "      <td>-1566.56</td>\n",
       "      <td>-1570.26</td>\n",
       "      <td>-1560.57</td>\n",
       "      <td>...</td>\n",
       "      <td>642.26</td>\n",
       "      <td>646.83</td>\n",
       "      <td>570.76</td>\n",
       "      <td>478.92</td>\n",
       "      <td>364.31</td>\n",
       "      <td>126.94</td>\n",
       "      <td>296.15</td>\n",
       "      <td>314.58</td>\n",
       "      <td>280.01</td>\n",
       "      <td>306.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4736</td>\n",
       "      <td>5.46</td>\n",
       "      <td>10.28</td>\n",
       "      <td>7.87</td>\n",
       "      <td>6.57</td>\n",
       "      <td>3.35</td>\n",
       "      <td>4.70</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2.43</td>\n",
       "      <td>2.45</td>\n",
       "      <td>3.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.45</td>\n",
       "      <td>-1.59</td>\n",
       "      <td>-3.60</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-7.06</td>\n",
       "      <td>0.72</td>\n",
       "      <td>-4.71</td>\n",
       "      <td>2.25</td>\n",
       "      <td>-2.96</td>\n",
       "      <td>8.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2812</td>\n",
       "      <td>2.70</td>\n",
       "      <td>-6.37</td>\n",
       "      <td>-13.93</td>\n",
       "      <td>-5.82</td>\n",
       "      <td>-4.59</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-2.37</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>4.70</td>\n",
       "      <td>-2.86</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.91</td>\n",
       "      <td>-0.48</td>\n",
       "      <td>-3.75</td>\n",
       "      <td>6.65</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>9.53</td>\n",
       "      <td>-4.82</td>\n",
       "      <td>-4.33</td>\n",
       "      <td>-6.72</td>\n",
       "      <td>-2.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 3197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       FLUX.1   FLUX.2   FLUX.3   FLUX.4   FLUX.5   FLUX.6   FLUX.7   FLUX.8  \\\n",
       "509  -1549.05 -1576.43 -1553.18 -1544.52 -1539.99 -1561.30 -1537.07 -1566.56   \n",
       "4736     5.46    10.28     7.87     6.57     3.35     4.70     3.96     2.43   \n",
       "2812     2.70    -6.37   -13.93    -5.82    -4.59    -1.29    -2.37    -0.92   \n",
       "\n",
       "       FLUX.9  FLUX.10  ...  FLUX.3188  FLUX.3189  FLUX.3190  FLUX.3191  \\\n",
       "509  -1570.26 -1560.57  ...     642.26     646.83     570.76     478.92   \n",
       "4736     2.45     3.69  ...      -2.45      -1.59      -3.60      -2.11   \n",
       "2812     4.70    -2.86  ...      -1.91      -0.48      -3.75       6.65   \n",
       "\n",
       "      FLUX.3192  FLUX.3193  FLUX.3194  FLUX.3195  FLUX.3196  FLUX.3197  \n",
       "509      364.31     126.94     296.15     314.58     280.01     306.14  \n",
       "4736      -7.06       0.72      -4.71       2.25      -2.96       8.83  \n",
       "2812      -2.17       9.53      -4.82      -4.33      -6.72      -2.13  \n",
       "\n",
       "[3 rows x 3197 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_test[1:4])\n",
    "print(X_test_array[1:4])\n",
    "X_test[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/utils/hostdir/capstone\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19OQIRfFhgEI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'tpot_checkpoint': File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir tpot_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h2AG5ChnL1Ss"
   },
   "outputs": [],
   "source": [
    "#print(np.shape(X_train_array), np.shape(X_test_array))\n",
    "\n",
    "exoplanet_model_tpot = TPOTClassifier(\n",
    "                          generations = 5,    #100: Number of iterations to the run pipeline optimization process. #TPOT will evaluate population_size + generations × offspring_size pipelines in total. \n",
    "                          population_size=10, #100: Number of individuals to retain in the genetic programming population every generation. \n",
    "                          offspring_size = 2, #None: Number of offspring to produce in each genetic programming generation. By default, the number of offspring is equal to the number of population size. \n",
    "                          mutation_rate=0.8,  #0.9: Mutation rate for the genetic programming algorithm in the range [0.0, 1.0] to random changes to every generation to those many pipelines. mutation_rate + crossover_rate cannot exceed 1.0.\n",
    "                          crossover_rate=0.2, #0.1: Crossover rate for the genetic programming algorithm in the range [0.0, 1.0] to breed those many pipelines every generation.  mutation_rate + crossover_rate cannot exceed 1.0. \n",
    "                          scoring='accuracy', #accuracy: One of the available scoring functions like 'accuracy', 'f1', 'precision', 'recall', 'roc_auc', etc\n",
    "                          cv=5,               #5: Cross-validation strategy used when evaluating pipelines. An integer or a cross-validation generator object or an iterable yielding train/test splits\n",
    "                          subsample = 1.0,    #1.0: Fraction of training samples that are used during the TPOT optimization process. Must be in the range (0.0, 1.0]. \n",
    "                          n_jobs = 2,         #1: Number of processes to use in parallel for evaluating pipelines during the TPOT optimization process. Setting n_jobs=-1 will use all cores, -2 will use all cores but one. Using more cores requires more memory.\n",
    "                          max_time_mins=120,  #None: How many minutes TPOT has to optimize the pipeline.If not None, this setting will override the generations parameter and allow TPOT to run until max_time_mins minutes elapse. \n",
    "                          max_eval_time_mins=5,    #5: How many minutes TPOT has to evaluate a single pipeline. Use this parameter to help prevent TPOT from wasting time on evaluating time-consuming pipelines. \n",
    "                          random_state=3,     #None: Integer. Use this parameter to make sure that TPOT will give you the same results each time you run it against the same data set with that seed.\n",
    "                          config_dict = None, #None: 'TPOT light', 'TPOT Spare', 'TPOT MDR', None or a python dictionary for custom config\n",
    "                       #   template = None,    #None: Template of predefined pipeline structure. \n",
    "                          warm_start = True,  #False: Flag indicating whether the TPOT instance will reuse the population from previous calls to fit(). \n",
    "                          memory = 'auto',    #None: 'auto' or a caching dir  path or Memory object or None. \n",
    "                          use_dask = False,   #False: Whether to use Dask-ML's pipeline optimiziations. This avoid re-fitting the same estimator on the same split of data multiple times. It will also provide more detailed diagnostics when using Dask's distributed scheduler. \n",
    "                          periodic_checkpoint_folder = '/rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint', #None: If supplied, a folder in which TPOT will periodically save pipelines in pareto front so far while optimizing.\n",
    "                          early_stop=None,    #None: Ends the optimization process if there is no improvement in the given number of generations. \n",
    "                          verbosity=3,        #0: 0 to 4.  How much information TPOT communicates while it's running. \n",
    "                       )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 775
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2831457,
     "status": "ok",
     "timestamp": 1563922461839,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "C8w2EXEZL07j",
    "outputId": "705fe9d7-7965-4d9e-cb27-6271b92dc8e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=10, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #1 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #3 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #9 due to time out. Continuing to the next pipeline.\n",
      "Saving periodic pipeline from pareto front to /rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint/pipeline_gen_1_idx_0_2019.09.09_12-01-43.py\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #23 due to time out. Continuing to the next pipeline.\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 6 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 7 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 8 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Skipped pipeline #32 due to time out. Continuing to the next pipeline.\n",
      "Generation 9 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 10 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Skipped pipeline #36 due to time out. Continuing to the next pipeline.\n",
      "Generation 11 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #39 due to time out. Continuing to the next pipeline.\n",
      "Generation 12 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 13 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 14 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #46 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #48 due to time out. Continuing to the next pipeline.\n",
      "Generation 15 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #50 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #52 due to time out. Continuing to the next pipeline.\n",
      "Generation 16 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 17 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #56 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #58 due to time out. Continuing to the next pipeline.\n",
      "Generation 18 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #60 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #62 due to time out. Continuing to the next pipeline.\n",
      "Generation 19 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 20 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 21 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #68 due to time out. Continuing to the next pipeline.\n",
      "Generation 22 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #71 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #73 due to time out. Continuing to the next pipeline.\n",
      "Generation 23 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 24 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Skipped pipeline #78 due to time out. Continuing to the next pipeline.\n",
      "Generation 25 - Current Pareto front scores:\n",
      "-1\t0.9925735525976321\tGradientBoostingClassifier(input_matrix, GradientBoostingClassifier__learning_rate=0.001, GradientBoostingClassifier__max_depth=5, GradientBoostingClassifier__max_features=0.2, GradientBoostingClassifier__min_samples_leaf=12, GradientBoostingClassifier__min_samples_split=19, GradientBoostingClassifier__n_estimators=100, GradientBoostingClassifier__subsample=1.0)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=False.\n",
      "\n",
      "120.35810015 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict=None, crossover_rate=0.2, cv=5,\n",
       "               disable_update_check=False, early_stop=None, generations=1000000,\n",
       "               max_eval_time_mins=5, max_time_mins=120, memory='auto',\n",
       "               mutation_rate=0.8, n_jobs=2, offspring_size=2,\n",
       "               periodic_checkpoint_folder='/rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint',\n",
       "               population_size=10, random_state=3, scoring='accuracy',\n",
       "               subsample=1.0, template='RandomTree', use_dask=False,\n",
       "               verbosity=3, warm_start=True)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tpot_exoplanet_3mins = TPOTClassifier(verbosity=2, max_time_mins=60)\n",
    "#tpot_exoplanet_3mins.fit(X_train_array, y_train)\n",
    "\n",
    "exoplanet_model_tpot.fit(X_train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=exoplanet_model_tpot.predict(X_test_array)\n",
    "y_train_pred=exoplanet_model_tpot.predict(X_train_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1840,
     "status": "ok",
     "timestamp": 1563922502398,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "1wDErfJ4NAD9",
    "outputId": "9a3a7d0f-ab08-4a97-af8b-4b234eedf749"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OYEqpGhHj2BA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ol3xh19Rj2ob"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9941060903732809\n",
      "F1 score: 0.9970443349753695\n",
      "Recall: 1.0\n",
      "Precision: 0.9941060903732809\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       506\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       509\n",
      "   macro avg       0.50      0.50      0.50       509\n",
      "weighted avg       0.99      0.99      0.99       509\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[506   0]\n",
      " [  3   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print('F1 score:', f1_score(y_test, y_pred))\n",
    "print('Recall:', recall_score(y_test, y_pred))\n",
    "print('Precision:', precision_score(y_test, y_pred))\n",
    "print('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1923,
     "status": "ok",
     "timestamp": 1563922518375,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "b_7azcavNAHw",
    "outputId": "d21d4c72-d23c-4ceb-b14b-e2e09117cdd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941060903732809\n"
     ]
    }
   ],
   "source": [
    "print(exoplanet_model_tpot.score(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9925731760594146\n",
      "F1 score: 0.9962727472045604\n",
      "Recall: 1.0\n",
      "Precision: 0.9925731760594146\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00      4544\n",
      "           2       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.99      4578\n",
      "   macro avg       0.50      0.50      0.50      4578\n",
      "weighted avg       0.99      0.99      0.99      4578\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[4544    0]\n",
      " [  34    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy:', accuracy_score(y_train, y_train_pred))\n",
    "print('F1 score:', f1_score(y_train, y_train_pred))\n",
    "print('Recall:', recall_score(y_train, y_train_pred))\n",
    "print('Precision:', precision_score(y_train, y_train_pred))\n",
    "print('\\n clasification report:\\n', classification_report(y_train, y_train_pred))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7522,
     "status": "ok",
     "timestamp": 1563923131596,
     "user": {
      "displayName": "Mahendran Mohan",
      "photoUrl": "",
      "userId": "02519250507792255562"
     },
     "user_tz": -330
    },
    "id": "yd27bBf5DTaL",
    "outputId": "cb42d6ef-e1ab-4c48-ce45-aa1fd3435d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 271030495 Sep  9 14:19 exotrain_processed.csv\r\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('/content/drive/My Drive/Colab Notebooks/AUTOML')\n",
    "#!head exotrain_processed.csv\n",
    "!ls -lrt exotrain_processed.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6KqvjBR4bLOq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\r\n",
      "import pandas as pd\r\n",
      "from sklearn.ensemble import GradientBoostingClassifier\r\n",
      "from sklearn.model_selection import train_test_split\r\n",
      "\r\n",
      "# NOTE: Make sure that the class is labeled 'target' in the data file\r\n",
      "tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)\r\n",
      "features = tpot_data.drop('target', axis=1).values\r\n",
      "training_features, testing_features, training_target, testing_target = \\\r\n",
      "            train_test_split(features, tpot_data['target'].values, random_state=3)\r\n",
      "\r\n",
      "# Average CV score on the training set was:0.9925735525976321\r\n",
      "exported_pipeline = GradientBoostingClassifier(learning_rate=0.001, max_depth=5, max_features=0.2, min_samples_leaf=12, min_samples_split=19, n_estimators=100, subsample=1.0)\r\n",
      "\r\n",
      "exported_pipeline.fit(training_features, training_target)\r\n",
      "results = exported_pipeline.predict(testing_features)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exoplanet_model_tpot.export('exoplanet_model_tpot.py')\n",
    "\n",
    "#tpot_model2.export('tpot_loanpred_model2_30mins.py')\n",
    "\n",
    "!cat exoplanet_model_tpot.py\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 307584 Sep  9 14:45 exoplanet_model_tpot_pickle.pkl\n",
      "0.9941060903732809\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "#exoplanet_model_tpot_pickle = pickle.dumps(exoplanet_model_tpot.fitted_pipeline_)\n",
    "#exoplanet_model_tpot1 = pickle.loads(tpot_exoplanet_model_pickle)\n",
    "# save the model to disk\n",
    "pickle.dump(exoplanet_model_tpot.fitted_pipeline_, open('exoplanet_model_tpot_pickle.pkl', 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "exoplanet_model_tpot1 = pickle.load(open('exoplanet_model_tpot_pickle.pkl', 'rb'))\n",
    "\n",
    "!ls -lrt exoplanet_model_tpot_pickle.pkl\n",
    "print(exoplanet_model_tpot.score(X_test_array, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941060903732809\n",
      "-rw-r--r-- 1 root root 412302 Sep  9 14:47 exoplanet_model_tpot.joblib\r\n"
     ]
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "dump(exoplanet_model_tpot.fitted_pipeline_, 'exoplanet_model_tpot.joblib')\n",
    "exoplanet_model_tpot2 = load('exoplanet_model_tpot.joblib')\n",
    "print(exoplanet_model_tpot2.score(X_test_array, y_test))\n",
    "!ls -lrt exoplanet_model_tpot.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "exoplanet_model_tpot_f1 = TPOTClassifier(\n",
    "                          generations = 5,    #100: Number of iterations to the run pipeline optimization process. #TPOT will evaluate population_size + generations × offspring_size pipelines in total. \n",
    "                          population_size=10, #100: Number of individuals to retain in the genetic programming population every generation. \n",
    "                          offspring_size = 2, #None: Number of offspring to produce in each genetic programming generation. By default, the number of offspring is equal to the number of population size. \n",
    "                          mutation_rate=0.8,  #0.9: Mutation rate for the genetic programming algorithm in the range [0.0, 1.0] to random changes to every generation to those many pipelines. mutation_rate + crossover_rate cannot exceed 1.0.\n",
    "                          crossover_rate=0.2, #0.1: Crossover rate for the genetic programming algorithm in the range [0.0, 1.0] to breed those many pipelines every generation.  mutation_rate + crossover_rate cannot exceed 1.0. \n",
    "                          scoring='f1_weighted', #accuracy: One of the available scoring functions like 'accuracy', 'f1', 'precision', 'recall', 'roc_auc', etc\n",
    "                          cv=5,               #5: Cross-validation strategy used when evaluating pipelines. An integer or a cross-validation generator object or an iterable yielding train/test splits\n",
    "                          subsample = 1.0,    #1.0: Fraction of training samples that are used during the TPOT optimization process. Must be in the range (0.0, 1.0]. \n",
    "                          n_jobs = 4,         #1: Number of processes to use in parallel for evaluating pipelines during the TPOT optimization process. Setting n_jobs=-1 will use all cores, -2 will use all cores but one. Using more cores requires more memory.\n",
    "                          max_time_mins=120,  #None: How many minutes TPOT has to optimize the pipeline.If not None, this setting will override the generations parameter and allow TPOT to run until max_time_mins minutes elapse. \n",
    "                          max_eval_time_mins=10,    #5: How many minutes TPOT has to evaluate a single pipeline. Use this parameter to help prevent TPOT from wasting time on evaluating time-consuming pipelines. \n",
    "                          random_state=3,     #None: Integer. Use this parameter to make sure that TPOT will give you the same results each time you run it against the same data set with that seed.\n",
    "                          config_dict = 'TPOT light', #None: 'TPOT light', 'TPOT Spare', 'TPOT MDR', None or a python dictionary for custom config\n",
    "                       #   template = None,    #None: Template of predefined pipeline structure. \n",
    "                          warm_start = False,  #False: Flag indicating whether the TPOT instance will reuse the population from previous calls to fit(). \n",
    "                          memory = 'auto',    #None: 'auto' or a caching dir  path or Memory object or None. \n",
    "                          use_dask = False,   #False: Whether to use Dask-ML's pipeline optimiziations. This avoid re-fitting the same estimator on the same split of data multiple times. It will also provide more detailed diagnostics when using Dask's distributed scheduler. \n",
    "                          periodic_checkpoint_folder = '/rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint2', #None: If supplied, a folder in which TPOT will periodically save pipelines in pareto front so far while optimizing.\n",
    "                          early_stop=None,    #None: Ends the optimization process if there is no improvement in the given number of generations. \n",
    "                          verbosity=3,        #0: 0 to 4.  How much information TPOT communicates while it's running. \n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=10, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #1 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #4 due to time out. Continuing to the next pipeline.\n",
      "Saving periodic pipeline from pareto front to /rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint2/pipeline_gen_1_idx_0_2019.09.09_15-09-42.py\n",
      "Generation 1 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "\n",
      "Skipped pipeline #15 due to time out. Continuing to the next pipeline.\n",
      "Generation 2 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 3 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Generation 4 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Saving periodic pipeline from pareto front to /rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint2/pipeline_gen_4_idx_1_2019.09.09_15-25-27.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 92.\n",
      "Generation 5 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 6 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 7 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 8 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 9 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 10 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative.\n",
      "Generation 11 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 12 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 13 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 14 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 15 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Generation 16 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative.\n",
      "Generation 17 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 18 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 19 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 20 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 21 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 22 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative.\n",
      "Generation 23 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Skipped pipeline #60 due to time out. Continuing to the next pipeline.\n",
      "Generation 24 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "Generation 25 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Skipped pipeline #66 due to time out. Continuing to the next pipeline.\n",
      "Generation 26 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='logistic_regression' are not supported when dual=True, Parameters: penalty='l1', loss='logistic_regression', dual=True.\n",
      "Generation 27 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 28 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 29 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 30 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 31 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 32 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 33 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Generation 34 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 35 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Generation 36 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 37 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Skipped pipeline #90 due to time out. Continuing to the next pipeline.\n",
      "Generation 38 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 39 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Generation 40 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Generation 41 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Generation 42 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Input X must be non-negative.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=1 Input X must be non-negative.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Generation 43 - Current Pareto front scores:\n",
      "-1\t0.9890767724740954\tDecisionTreeClassifier(input_matrix, DecisionTreeClassifier__criterion=entropy, DecisionTreeClassifier__max_depth=4, DecisionTreeClassifier__min_samples_leaf=11, DecisionTreeClassifier__min_samples_split=13)\n",
      "-3\t0.9893647051551483\tDecisionTreeClassifier(BernoulliNB(RobustScaler(input_matrix), BernoulliNB__alpha=100.0, BernoulliNB__fit_prior=False), DecisionTreeClassifier__criterion=gini, DecisionTreeClassifier__max_depth=2, DecisionTreeClassifier__min_samples_leaf=18, DecisionTreeClassifier__min_samples_split=3)\n",
      "\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "Periodic pipeline was not saved, probably saved before...\n",
      "\n",
      "120.14713993333334 minutes have elapsed. TPOT will close down.\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTClassifier(config_dict='TPOT light', crossover_rate=0.2, cv=5,\n",
       "               disable_update_check=False, early_stop=None, generations=1000000,\n",
       "               max_eval_time_mins=10, max_time_mins=120, memory='auto',\n",
       "               mutation_rate=0.8, n_jobs=4, offspring_size=2,\n",
       "               periodic_checkpoint_folder='/rapids/notebooks/utils/hostdir/capstone/tpot_checkpoint2',\n",
       "               population_size=10, random_state=3, scoring='f1_weighted',\n",
       "               subsample=1.0, template='RandomTree', use_dask=False,\n",
       "               verbosity=3, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exoplanet_model_tpot_f1.fit(X_train_array, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 307584 Sep  9 14:45 exoplanet_model_tpot_pickle.pkl\n",
      "0.9941060903732809\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "#exoplanet_model_tpot_pickle = pickle.dumps(exoplanet_model_tpot.fitted_pipeline_)\n",
    "#exoplanet_model_tpot1 = pickle.loads(tpot_exoplanet_model_pickle)\n",
    "# save the model to disk\n",
    "pickle.dump(exoplanet_model_tpot_f1.fitted_pipeline_, open('exoplanet_model_tpot_pickle_f1.pkl', 'wb'))\n",
    "\n",
    "# load the model from disk\n",
    "exoplanet_model_tpot1_f1_load = pickle.load(open('exoplanet_model_tpot_pickle_f1.pkl', 'rb'))\n",
    "\n",
    "!ls -lrt exoplanet_model_tpot_pickle.pkl\n",
    "print(exoplanet_model_tpot1_f1_load.score(X_test_array, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9925731760594146\n",
      "F1 score: 0.9962727472045604\n",
      "Recall: 1.0\n",
      "Precision: 0.9925731760594146\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00      4544\n",
      "           2       0.00      0.00      0.00        34\n",
      "\n",
      "    accuracy                           0.99      4578\n",
      "   macro avg       0.50      0.50      0.50      4578\n",
      "weighted avg       0.99      0.99      0.99      4578\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[4544    0]\n",
      " [  34    0]]\n",
      "Accuracy: 0.9941060903732809\n",
      "F1 score: 0.9970443349753695\n",
      "Recall: 1.0\n",
      "Precision: 0.9941060903732809\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.99      1.00      1.00       506\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.99       509\n",
      "   macro avg       0.50      0.50      0.50       509\n",
      "weighted avg       0.99      0.99      0.99       509\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[506   0]\n",
      " [  3   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/conda/envs/rapids/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_pred2=exoplanet_model_tpot1_f1_load.predict(X_test_array)\n",
    "y_train_pred2=exoplanet_model_tpot1_f1_load.predict(X_train_array)\n",
    "print('Accuracy:', accuracy_score(y_train, y_train_pred2))\n",
    "print('F1 score:', f1_score(y_train, y_train_pred2))\n",
    "print('Recall:', recall_score(y_train, y_train_pred2))\n",
    "print('Precision:', precision_score(y_train, y_train_pred2))\n",
    "print('\\n clasification report:\\n', classification_report(y_train, y_train_pred2))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_train, y_train_pred2))\n",
    "\n",
    "print('Accuracy:', accuracy_score(y_test, y_pred2))\n",
    "print('F1 score:', f1_score(y_test, y_pred2))\n",
    "print('Recall:', recall_score(y_test, y_pred2))\n",
    "print('Precision:', precision_score(y_test, y_pred2))\n",
    "print('\\n clasification report:\\n', classification_report(y_test,y_pred2))\n",
    "print('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AUTOML_tpot_capstone.ipynb",
   "provenance": [
    {
     "file_id": "1SXIdjqZZLVUKKw8xECJS0XFgAWjWs6ry",
     "timestamp": 1563907830135
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
